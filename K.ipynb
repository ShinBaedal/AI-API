{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"K.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1VC7OUjJdRsV0JnJCDLtwqcgWdSMdfJaD","authorship_tag":"ABX9TyMqjF9qKJCQyMIwPAGePlZC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa2efb01968e4866bc159bc4cecd0bb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5d68f8514f164ed5926435363da25ff0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_38a12259fd784a2db03b023c2c6bdd06","IPY_MODEL_a5de8b694e254622a23dd90908958a50","IPY_MODEL_6a64b44bdaa14476900b59560c42ac6c"]}},"5d68f8514f164ed5926435363da25ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38a12259fd784a2db03b023c2c6bdd06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_80137a6b147c4998a6d6d79d074512a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e2c3e4656616405788a3891059ae15cf"}},"a5de8b694e254622a23dd90908958a50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8e436789a9b24f38b70a2fdeb278af41","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":204,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":204,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68a67067ead6482c847e9d9543e64ae8"}},"6a64b44bdaa14476900b59560c42ac6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_877776072ad94757bd4c8b09a4a6b898","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 204/204 [01:58&lt;00:00,  2.26it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1c75924b969438793e1458ad9ca3d80"}},"80137a6b147c4998a6d6d79d074512a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e2c3e4656616405788a3891059ae15cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e436789a9b24f38b70a2fdeb278af41":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68a67067ead6482c847e9d9543e64ae8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"877776072ad94757bd4c8b09a4a6b898":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1c75924b969438793e1458ad9ca3d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d0986e6e2e744df8d3930d952582026":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d0329b4a77a740a7b0afbd481a0c4fe4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_16b7a877cdcc412e868153742ecbf084","IPY_MODEL_c1f46bb172bb40edba12ea554f3d60ee","IPY_MODEL_0a821a427ab449eba041393d00ffcc35"]}},"d0329b4a77a740a7b0afbd481a0c4fe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16b7a877cdcc412e868153742ecbf084":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_76e69184e256450d8da1e91d7ec5d1d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62885dcfd5f34556861309dacadb430c"}},"c1f46bb172bb40edba12ea554f3d60ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6fb42fc1fd864d7594ffa07d2da56fd5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":19,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":19,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51e4dd117318482981c9ddf5d1fd375b"}},"0a821a427ab449eba041393d00ffcc35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0352949752e54f8d9de5c27a1e49be09","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 19/19 [00:04&lt;00:00,  5.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_622f7a78ffc84f90b4c2b1ac55a3ad7b"}},"76e69184e256450d8da1e91d7ec5d1d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"62885dcfd5f34556861309dacadb430c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fb42fc1fd864d7594ffa07d2da56fd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51e4dd117318482981c9ddf5d1fd375b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0352949752e54f8d9de5c27a1e49be09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"622f7a78ffc84f90b4c2b1ac55a3ad7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0032c7794cb145229e80c39d4cdc7289":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9b6d74529a0c4c2b9dede3746c8e4939","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_59458103e8724ff4b1017e59b604b10d","IPY_MODEL_f26a5b187de142bfabf683d8a1a37cdb","IPY_MODEL_2f04cb726f2d49c4844ec651884ee23f"]}},"9b6d74529a0c4c2b9dede3746c8e4939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59458103e8724ff4b1017e59b604b10d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8a379821b16a469286e2f006ba0b9111","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62e9a80b866c4e60981c283c5b42d28e"}},"f26a5b187de142bfabf683d8a1a37cdb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f11fb08759d941bea5016039239e4f44","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":204,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":204,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d4873a730b44123a988aabd6c4daa62"}},"2f04cb726f2d49c4844ec651884ee23f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83ec91dcf5a74ccf8b9638731abd72ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 204/204 [01:58&lt;00:00,  2.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e813280a2a14cab8a04d16385509260"}},"8a379821b16a469286e2f006ba0b9111":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"62e9a80b866c4e60981c283c5b42d28e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f11fb08759d941bea5016039239e4f44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d4873a730b44123a988aabd6c4daa62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83ec91dcf5a74ccf8b9638731abd72ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e813280a2a14cab8a04d16385509260":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32b4e9866eb942978e944aa2b4fc2d8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ef87a1f82425451792774ad3135df80d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_56996f02173c47d29d60c77613606036","IPY_MODEL_b010d476caa3436391339991aff52b56","IPY_MODEL_2a156a9c3ad54a52a1343261028114cd"]}},"ef87a1f82425451792774ad3135df80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56996f02173c47d29d60c77613606036":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8cd594b3750404aae202080c53c0b35","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 89%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99c8e23b06504e81aeaa03b3136d1bed"}},"b010d476caa3436391339991aff52b56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d6ad685ba184fe89defd09070f2d563","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":19,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":17,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49111090e7e44d2caaebcf3cf92b4365"}},"2a156a9c3ad54a52a1343261028114cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d195c7863004e35aea1f97dcc4acd36","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 17/19 [00:03&lt;00:00,  5.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c7d5787b16242138ca1378968165b24"}},"f8cd594b3750404aae202080c53c0b35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99c8e23b06504e81aeaa03b3136d1bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d6ad685ba184fe89defd09070f2d563":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"49111090e7e44d2caaebcf3cf92b4365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d195c7863004e35aea1f97dcc4acd36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4c7d5787b16242138ca1378968165b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a13m6pVsyTB3","executionInfo":{"status":"ok","timestamp":1637835765736,"user_tz":-540,"elapsed":662,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"43f7a624-3493-4304-c55f-93864cb17ce1"},"source":["cd drive/Othercomputers/내 노트북/googleDrive/Hackathon/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/내 노트북/googleDrive/Hackathon\n"]}]},{"cell_type":"code","metadata":{"id":"vVheMXmIZqw3","executionInfo":{"status":"ok","timestamp":1637820686404,"user_tz":-540,"elapsed":515,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["data = open('./dataset.txt')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHXWwjfoZzRU","executionInfo":{"status":"ok","timestamp":1637816346947,"user_tz":-540,"elapsed":649,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["mal = []\n","zero = []\n","j = ''\n","k = ''\n","while True:\n","    line = data.readline()\n","    if not line: break\n","    i = line.split('|')\n","    mal.append(i[0])\n","    zero.append(i[1])"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIVZvU8pbMXP","executionInfo":{"status":"ok","timestamp":1637816550919,"user_tz":-540,"elapsed":553,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["for i in range(len(zero)):\n","    zero[i] = zero[i].replace('\\n', '')"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"NbZI4_MReVCx","executionInfo":{"status":"ok","timestamp":1637816753275,"user_tz":-540,"elapsed":539,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"2bbe81ff-2641-44e1-df9b-1d4c96e270d7"},"source":["D = pd.DataFrame({'comments' : mal, 'contain_gender_bias' : zero})\n","D"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comments</th>\n","      <th>contain_gender_bias</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>좌배 까는건 ㅇㅂ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>세탁이라고 봐도 된다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5820</th>\n","      <td>좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5821</th>\n","      <td>세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5822</th>\n","      <td>너가 한 말 중에</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5823</th>\n","      <td>제갈대중 ㅇㅂ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5824</th>\n","      <td>우리나라교회는 악마들이모여 주뎅이 처벌리고</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5825 rows × 2 columns</p>\n","</div>"],"text/plain":["                                               comments contain_gender_bias\n","0                                             좌배 까는건 ㅇㅂ                   1\n","1                          집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ                   0\n","2           개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아                   1\n","3                                           세탁이라고 봐도 된다                   0\n","4                                    애새끼가 초딩도 아니고 ㅋㅋㅋㅋ                    1\n","...                                                 ...                 ...\n","5820         좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임                   0\n","5821  세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...                   1\n","5822                                          너가 한 말 중에                   0\n","5823                                            제갈대중 ㅇㅂ                   0\n","5824                           우리나라교회는 악마들이모여 주뎅이 처벌리고                    1\n","\n","[5825 rows x 2 columns]"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"pY2wmHMQx3uu","executionInfo":{"status":"ok","timestamp":1637814459464,"user_tz":-540,"elapsed":1796,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["import pandas as pd \n","\n","train = pd.read_csv('./train.csv')\n","dev = pd.read_csv('./dev.csv')\n","#dataCombine = pd.concat([train, dev], axis=0, ignore_index=True) # concat함수를 이용해서 리스트의 내용을 병합\n","#dataCombine.to_csv('total.csv', index=False)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"x_dsKwHRF516","executionInfo":{"status":"ok","timestamp":1637816896533,"user_tz":-540,"elapsed":485,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"69626042-0b01-4c97-ba0b-bfb8ee8b4232"},"source":["total = pd.read_csv('./total.csv')\n","total.drop(['bias', 'hate'], axis=1, inplace=True)\n","total"],"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comments</th>\n","      <th>contain_gender_bias</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8362</th>\n","      <td>지현우 범죄 저지르지 않았나요?</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8363</th>\n","      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8364</th>\n","      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8365</th>\n","      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8366</th>\n","      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8367 rows × 2 columns</p>\n","</div>"],"text/plain":["                                               comments  contain_gender_bias\n","0     (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False\n","1     ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False\n","2     ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False\n","3                    1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False\n","4     1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True\n","...                                                 ...                  ...\n","8362                                  지현우 범죄 저지르지 않았나요?                False\n","8363                                    여자인생 망칠 일 있나 ㅋㅋ                 True\n","8364            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?                False\n","8365  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...                 True\n","8366  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...                 True\n","\n","[8367 rows x 2 columns]"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"IfUvk3YsTkY2","executionInfo":{"status":"ok","timestamp":1637816901182,"user_tz":-540,"elapsed":576,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["final = pd.concat([total, D], axis=0, ignore_index=True)\n","final.to_csv('./final.csv', index=False)"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"fztntkvV4OVu","executionInfo":{"status":"ok","timestamp":1637814460466,"user_tz":-540,"elapsed":28,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["train.drop(['bias', 'hate'], axis=1, inplace=True)\n","dev.drop(['bias', 'hate'], axis=1, inplace=True)\n","total.drop(['bias', 'hate'], axis=1, inplace=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oHwvclDTxou","executionInfo":{"status":"ok","timestamp":1637817071845,"user_tz":-540,"elapsed":598,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"bf554cc5-ab80-413d-8b78-22b697f2d705"},"source":["len(final)"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14192"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"F2YROJ2DgyyU","executionInfo":{"status":"ok","timestamp":1637835789466,"user_tz":-540,"elapsed":989,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["import pandas as pd \n","\n","final = pd.read_csv('./final.csv')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eOKQrahpiRC","executionInfo":{"status":"ok","timestamp":1637835789466,"user_tz":-540,"elapsed":3,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["df_shuffled=final.sample(frac=1).reset_index(drop=True)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwb8mHWKPQHM","executionInfo":{"status":"ok","timestamp":1637835789467,"user_tz":-540,"elapsed":4,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["#train.to_csv('./train.tsv', index=False)\n","#dev.to_csv('./dev.tsv', index=False)\n","\n","dataset_train = []\n","dataset_test = []\n","count = 0\n","\n","for i in range(0, 13000):\n","    dataset_train.append([])\n","    dataset_train[i].append(df_shuffled['comments'][count])\n","    if df_shuffled['contain_gender_bias'][count] == 'False' or df_shuffled['contain_gender_bias'][count] == '0':\n","        dataset_train[i].append(0)\n","    else : dataset_train[i].append(1)\n","    count += 1\n","\n","for i in range(0, 1192):\n","    dataset_test.append([])\n","    dataset_test[i].append(df_shuffled['comments'][count])\n","    if df_shuffled['contain_gender_bias'][count] == 'False' or df_shuffled['contain_gender_bias'][count] == '0':\n","        dataset_test[i].append(0)\n","    else : dataset_test[i].append(1)\n","    count += 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"krsCgzr6T-3G","executionInfo":{"status":"error","timestamp":1637835790306,"user_tz":-540,"elapsed":55,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"0859a087-6ac7-4991-d7fd-329cc4e53a82"},"source":["dataset_train[14000]"],"execution_count":5,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-48400d410f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"1KsjSfV0Hz3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637835814668,"user_tz":-540,"elapsed":23570,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"9aae2bb6-2d04-4c56-ee20-8ead97e54085"},"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3\n","!pip install torch"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n","\u001b[K     |████████████████████████████████| 46.9 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.6)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595738 sha256=dcde2b37a26391da8fb6c54d6c0006f0a16c5cf6a0e5769d93dadbad81f27dab\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 9.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==3\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 39.6 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 52.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (3.0.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.8.0rc4 transformers-3.0.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVhuiyMGKVwk","executionInfo":{"status":"ok","timestamp":1637835819543,"user_tz":-540,"elapsed":4882,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"44859db8-edc3-40c2-bc11-52c6b856f5b8"},"source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-ggvwdzd5\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-ggvwdzd5\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12771 sha256=64c541c47e3eba4fc463f37f41d42f6176b7758dcd6805bb14e2a43487c11c6d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bhr1d9r7/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: kobert\n","Successfully installed kobert-0.1.2\n"]}]},{"cell_type":"code","metadata":{"id":"_nQKMpAUKbWJ","executionInfo":{"status":"ok","timestamp":1637835826445,"user_tz":-540,"elapsed":6904,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpSTuljBKeyh","executionInfo":{"status":"ok","timestamp":1637835828908,"user_tz":-540,"elapsed":2473,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"1WxHrfCnKg5O","executionInfo":{"status":"ok","timestamp":1637835828908,"user_tz":-540,"elapsed":3,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1VW_7msKi2K","executionInfo":{"status":"ok","timestamp":1637835828909,"user_tz":-540,"elapsed":3,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["##GPU 사용 시\n","device = torch.device(\"cuda:0\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OijncIDKlP4","executionInfo":{"status":"ok","timestamp":1637835869686,"user_tz":-540,"elapsed":40780,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"a07a87f4-9248-4952-aa2b-e538ba7012d2"},"source":["bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[██████████████████████████████████████████████████]\n","[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","metadata":{"id":"UVo_1OpyKnKz","executionInfo":{"status":"ok","timestamp":1637835869687,"user_tz":-540,"elapsed":29,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["#dataset_train = nlp.data.TSVDataset(\"train.tsv\", field_indices=[0,2])\n","#dataset_test = nlp.data.TSVDataset(\"dev.tsv\", field_indices=[0,2])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyHwShOxVft9","executionInfo":{"status":"ok","timestamp":1637835869687,"user_tz":-540,"elapsed":27,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"a80211f8-ad91-48a6-ed34-a06d1053694f"},"source":["tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"CY900HZKWim-","executionInfo":{"status":"ok","timestamp":1637835869688,"user_tz":-540,"elapsed":20,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","        #self.labels = [j for i, j in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"XesfMo24WmbM","executionInfo":{"status":"ok","timestamp":1637835869688,"user_tz":-540,"elapsed":19,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["## Setting parameters\n","max_len = 100\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 4\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJt_H2TrWtin","executionInfo":{"status":"ok","timestamp":1637835871026,"user_tz":-540,"elapsed":1356,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvaTHIj1W1yZ","executionInfo":{"status":"ok","timestamp":1637835871026,"user_tz":-540,"elapsed":8,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"7c2b4384-c8a3-4ad1-b745-386e82d0e1fa"},"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"2emQDsZZW5I0","executionInfo":{"status":"ok","timestamp":1637835871026,"user_tz":-540,"elapsed":5,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=2,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"wmtdidUeW9Rl","executionInfo":{"status":"ok","timestamp":1637835881450,"user_tz":-540,"elapsed":10428,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZHywCRQXGw0","executionInfo":{"status":"ok","timestamp":1637835881453,"user_tz":-540,"elapsed":22,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScmIPwe0Yh0r","executionInfo":{"status":"ok","timestamp":1637835881453,"user_tz":-540,"elapsed":21,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImQCtlAQYkuz","executionInfo":{"status":"ok","timestamp":1637835881454,"user_tz":-540,"elapsed":22,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOQSYfskYnT7","executionInfo":{"status":"ok","timestamp":1637835881454,"user_tz":-540,"elapsed":21,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-qM5-9HYp26","executionInfo":{"status":"ok","timestamp":1637835881455,"user_tz":-540,"elapsed":22,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Qem2sfQeMKH","executionInfo":{"status":"ok","timestamp":1637835881455,"user_tz":-540,"elapsed":21,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfuqRalkYsOa","colab":{"base_uri":"https://localhost:8080/","height":792,"referenced_widgets":["aa2efb01968e4866bc159bc4cecd0bb4","5d68f8514f164ed5926435363da25ff0","38a12259fd784a2db03b023c2c6bdd06","a5de8b694e254622a23dd90908958a50","6a64b44bdaa14476900b59560c42ac6c","80137a6b147c4998a6d6d79d074512a1","e2c3e4656616405788a3891059ae15cf","8e436789a9b24f38b70a2fdeb278af41","68a67067ead6482c847e9d9543e64ae8","877776072ad94757bd4c8b09a4a6b898","e1c75924b969438793e1458ad9ca3d80","8d0986e6e2e744df8d3930d952582026","d0329b4a77a740a7b0afbd481a0c4fe4","16b7a877cdcc412e868153742ecbf084","c1f46bb172bb40edba12ea554f3d60ee","0a821a427ab449eba041393d00ffcc35","76e69184e256450d8da1e91d7ec5d1d8","62885dcfd5f34556861309dacadb430c","6fb42fc1fd864d7594ffa07d2da56fd5","51e4dd117318482981c9ddf5d1fd375b","0352949752e54f8d9de5c27a1e49be09","622f7a78ffc84f90b4c2b1ac55a3ad7b","0032c7794cb145229e80c39d4cdc7289","9b6d74529a0c4c2b9dede3746c8e4939","59458103e8724ff4b1017e59b604b10d","f26a5b187de142bfabf683d8a1a37cdb","2f04cb726f2d49c4844ec651884ee23f","8a379821b16a469286e2f006ba0b9111","62e9a80b866c4e60981c283c5b42d28e","f11fb08759d941bea5016039239e4f44","3d4873a730b44123a988aabd6c4daa62","83ec91dcf5a74ccf8b9638731abd72ae","2e813280a2a14cab8a04d16385509260","32b4e9866eb942978e944aa2b4fc2d8a","ef87a1f82425451792774ad3135df80d","56996f02173c47d29d60c77613606036","b010d476caa3436391339991aff52b56","2a156a9c3ad54a52a1343261028114cd","f8cd594b3750404aae202080c53c0b35","99c8e23b06504e81aeaa03b3136d1bed","7d6ad685ba184fe89defd09070f2d563","49111090e7e44d2caaebcf3cf92b4365","4d195c7863004e35aea1f97dcc4acd36","4c7d5787b16242138ca1378968165b24"]},"executionInfo":{"status":"error","timestamp":1637836127032,"user_tz":-540,"elapsed":245598,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"1e19c466-14e4-4c02-c0a7-3292d9bb6f79"},"source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa2efb01968e4866bc159bc4cecd0bb4","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/204 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1 batch id 1 loss 0.6299330592155457 train acc 0.6875\n","epoch 1 batch id 201 loss 0.37883618474006653 train acc 0.7896455223880597\n","epoch 1 train acc 0.7896752450980392\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d0986e6e2e744df8d3930d952582026","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/19 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1 test acc 0.8583881578947368\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0032c7794cb145229e80c39d4cdc7289","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/204 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 2 batch id 1 loss 0.366094708442688 train acc 0.859375\n","epoch 2 batch id 201 loss 0.3251791000366211 train acc 0.8768656716417911\n","epoch 2 train acc 0.8763786764705882\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32b4e9866eb942978e944aa2b4fc2d8a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/19 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-e6a38b13095b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {} test acc {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-9e25613a1eab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mnew_context_layer_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_context_layer_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.06 GiB already allocated; 21.75 MiB free; 14.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"id":"A0XgQNi1pOpl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637824741597,"user_tz":-540,"elapsed":415,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"f06cde21-dbb8-44f0-8633-bedf5ae93756"},"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(False)\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(True)\n","\n","        print(test_eval[0])"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"E7Vta5YiQQ_m"},"source":["end = 1\n","while end == 1 :\n","    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLgxghWlYujt","executionInfo":{"status":"ok","timestamp":1637824903560,"user_tz":-540,"elapsed":7954,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["torch.save(model.state_dict(), './model.pt')"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej9u5Ogiv9nH","executionInfo":{"status":"aborted","timestamp":1637815321054,"user_tz":-540,"elapsed":12,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOCUB52NwNrh","executionInfo":{"status":"aborted","timestamp":1637815321055,"user_tz":-540,"elapsed":13,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["model.load_state_dict(torch.load('./model.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VJbA7IGwYeT","executionInfo":{"status":"aborted","timestamp":1637815321056,"user_tz":-540,"elapsed":14,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"source":["t = torch.tensor(1)\n","z = t.long().to(device)\n","print(z)"],"execution_count":null,"outputs":[]}]}